<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Parallel I/O · PencilArrays.jl</title><link href="https://jipolanco.github.io/PencilArrays.jl/PencilIO/" rel="canonical"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script data-main="../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/><script src="../assets/tomate.js"></script><script data-outdated-warner="">function maybeAddWarning () {
    const head = document.getElementsByTagName('head')[0];

    // Add a noindex meta tag (unless one exists) so that search engines don't index this version of the docs.
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        head.appendChild(meta);
    };

    // Add a stylesheet to avoid inline styling
    const style = document.createElement('style');
    style.type = 'text/css';
    style.appendChild(document.createTextNode('.outdated-warning-overlay {  position: fixed;  top: 0;  left: 0;  right: 0;  box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);  z-index: 999;  background-color: #ffaba7;  color: rgba(0, 0, 0, 0.7);  border-bottom: 3px solid #da0b00;  padding: 10px 35px;  text-align: center;  font-size: 15px; }  .outdated-warning-overlay .outdated-warning-closer {    position: absolute;    top: calc(50% - 10px);    right: 18px;    cursor: pointer;    width: 12px; }  .outdated-warning-overlay a {    color: #2e63b8; }    .outdated-warning-overlay a:hover {      color: #363636; }'));
    head.appendChild(style);

    const div = document.createElement('div');
    div.classList.add('outdated-warning-overlay');
    const closer = document.createElement('div');
    closer.classList.add('outdated-warning-closer');

    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This is an old version of the documentation. <br> <a href="' + href + '">Go to the newest version</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', maybeAddWarning);
} else {
    maybeAddWarning();
};
</script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img alt="PencilArrays.jl logo" src="../assets/logo.svg"/></a><div class="docs-package-name"><span class="docs-autofit">PencilArrays.jl</span></div><form action="../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../MPITopology/">MPI topology</a></li><li><a class="tocitem" href="../Pencils/">Pencil configurations</a></li><li><a class="tocitem" href="../PencilArrays/">Array wrappers</a></li><li><a class="tocitem" href="../Transpositions/">Global MPI operations</a></li><li class="is-active"><a class="tocitem" href="">Parallel I/O</a><ul class="internal"><li><a class="tocitem" href="#Getting-started"><span>Getting started</span></a></li><li><a class="tocitem" href="#setting_up_parallel_hdf5"><span>Setting-up Parallel HDF5</span></a></li><li><a class="tocitem" href="#Library"><span>Library</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li><li><a class="tocitem" href="../PencilArrays_timers/">Measuring performance</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Library</a></li><li class="is-active"><a href="">Parallel I/O</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Parallel I/O</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/jipolanco/PencilArrays.jl/blob/master/docs/src/PencilIO.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="PencilIO_module"><a class="docs-heading-anchor" href="#PencilIO_module">Parallel I/O</a><a id="PencilIO_module-1"></a><a class="docs-heading-anchor-permalink" href="#PencilIO_module" title="Permalink"></a></h1><p>The <code>PencilArrays.PencilIO</code> module contains functions for saving and loading <a href="../PencilArrays/#PencilArrays.PencilArray"><code>PencilArray</code></a>s to disk using parallel I/O. Currently, two different output formats are supported:</p><ul><li>raw binary files via the MPI-IO interface;</li><li>parallel HDF5 files.</li></ul><p>In both cases, information on dataset sizes, names and other metadata are included along with the binary data.</p><p>The implemented approach consists in storing the data coming from different MPI processes in a single file. This strategy scales better in terms of number of files, and is more convenient, than that of storing one file per process. However, the performance is very sensitive to the configuration of the underlying file system. In distributed file systems such as <a href="https://en.wikipedia.org/wiki/Lustre_(file_system)">Lustre</a>, it is worth tuning parameters such as the stripe count and stripe size. For more information, see for instance the <a href="https://portal.hdfgroup.org/display/HDF5/Parallel+HDF5">Parallel HDF5 page</a>.</p><h2 id="Getting-started"><a class="docs-heading-anchor" href="#Getting-started">Getting started</a><a id="Getting-started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-started" title="Permalink"></a></h2><p>The first step before writing <code>PencilArray</code>s is to choose the parallel I/O driver, which determines the format of the output data. Two different drivers are currently available:</p><ul><li><p><a href="#PencilArrays.PencilIO.MPIIODriver"><code>MPIIODriver</code></a>: parallel I/O via the MPI-IO API and the <a href="https://juliaparallel.github.io/MPI.jl/latest/io/">MPI.jl wrappers</a>. This driver writes a raw binary file, along with a JSON file describing dataset metadata (name, dimensions, location in file, ...);</p></li><li><p><a href="#PencilArrays.PencilIO.PHDF5Driver"><code>PHDF5Driver</code></a>: parallel I/O via the Parallel HDF5 API and <a href="https://github.com/JuliaIO/HDF5.jl">HDF5.jl</a>. This driver requires a special set-up, as detailed in the <a href="#setting_up_parallel_hdf5">dedicated section</a>.</p></li></ul><h3 id="Writing-data"><a class="docs-heading-anchor" href="#Writing-data">Writing data</a><a id="Writing-data-1"></a><a class="docs-heading-anchor-permalink" href="#Writing-data" title="Permalink"></a></h3><p>To open a parallel file, pass the MPI communicator and an instance of the chosen driver to <a href="#Base.open"><code>open</code></a>. For instance, the following opens an MPI-IO file in write mode:</p><pre><code class="language-julia">ff = open(MPIIODriver(), "filename.bin", MPI.COMM_WORLD; write=true)</code></pre><p>Datasets, in the form of <code>PencilArray</code>s, can then be written as follows:</p><pre><code class="language-julia">v = PencilArray(...)
ff["velocity"] = v</code></pre><p>This writing step may be customised via keyword arguments such as <code>chunks</code> and <code>collective</code>. These options are supported by both MPI-IO and HDF5 drivers. For instance:</p><pre><code class="language-julia">ff["velocity", chunks=true, collective=false] = v</code></pre><p>See <a href="#Base.setindex!"><code>setindex!</code></a> for the meaning of these options for each driver, as well as for driver-specific options.</p><p>After datasets are written, the file should be closed as usual by doing <code>close(ff)</code>. Note that the do-block syntax is also supported, as in</p><pre><code class="language-julia">open(MPIIODriver(), "filename.bin", MPI.COMM_WORLD; write=true) do ff
    ff["velocity"] = v
end</code></pre><h3 id="Reading-data"><a class="docs-heading-anchor" href="#Reading-data">Reading data</a><a id="Reading-data-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-data" title="Permalink"></a></h3><p>Data is loaded into an existent <code>PencilArray</code> using <a href="#Base.read!"><code>read!</code></a>. For instance:</p><pre><code class="language-julia">v = PencilArray(...)
ff = open(MPIIODriver(), "filename.bin", MPI.COMM_WORLD; read=true)
    read!(ff, v, "velocity")
end</code></pre><p>Note that, for the MPI-IO driver, a <code>filename.bin.json</code> file must be present along with the <code>filename.bin</code> file containing the binary data. The JSON file is automatically generated when writing data with this driver.</p><p>Optional keyword arguments, such as <code>collective</code>, are also supported by <a href="#Base.read!"><code>read!</code></a>.</p><h2 id="setting_up_parallel_hdf5"><a class="docs-heading-anchor" href="#setting_up_parallel_hdf5">Setting-up Parallel HDF5</a><a id="setting_up_parallel_hdf5-1"></a><a class="docs-heading-anchor-permalink" href="#setting_up_parallel_hdf5" title="Permalink"></a></h2><p>If using the <a href="#PencilArrays.PencilIO.PHDF5Driver">Parallel HDF5 driver</a>, the HDF5.jl package must be available and configured with MPI support. Note that HDF5.jl versions previous to <a href="https://github.com/JuliaIO/HDF5.jl/releases/tag/v0.15.0">v0.15</a> are not supported.</p><p>Parallel HDF5 is not enabled in the default installation of HDF5.jl. For Parallel HDF5 to work, the HDF5 C libraries wrapped by HDF5.jl must be compiled with parallel support and linked to the specific MPI implementation that will be used for parallel I/O. HDF5.jl must be explicitly instructed to use parallel-enabled HDF5 libraries available in the system. Similarly, MPI.jl must be instructed to use the corresponding MPI libraries. This is detailed in the sections below.</p><p>Parallel-enabled HDF5 libraries are usually included in computing clusters and linked to the available MPI implementations. They are also available via the package manager of a number of Linux distributions. (For instance, Fedora includes the <code>hdf5-mpich-devel</code> and <code>hdf5-openmpi-devel</code> packages, respectively linked to the MPICH and OpenMPI libraries in the Fedora repositories.)</p><p>The following step-by-step guide assumes one already has access to parallel-enabled HDF5 libraries linked to an existent MPI installation.</p><h3 id=".-Using-system-provided-MPI-libraries"><a class="docs-heading-anchor" href="#.-Using-system-provided-MPI-libraries">1. Using system-provided MPI libraries</a><a id=".-Using-system-provided-MPI-libraries-1"></a><a class="docs-heading-anchor-permalink" href="#.-Using-system-provided-MPI-libraries" title="Permalink"></a></h3><p>Set the environment variable <code>JULIA_MPI_BINARY=system</code> and then run <code>]build MPI</code> from Julia. For more control, one can also set the <code>JULIA_MPI_PATH</code> environment variable to the top-level installation directory of the MPI library.</p><p>See the <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/#Using-a-system-provided-MPI-1">MPI.jl docs</a> for details.</p><h3 id=".-Using-parallel-HDF5-libraries"><a class="docs-heading-anchor" href="#.-Using-parallel-HDF5-libraries">2. Using parallel HDF5 libraries</a><a id=".-Using-parallel-HDF5-libraries-1"></a><a class="docs-heading-anchor-permalink" href="#.-Using-parallel-HDF5-libraries" title="Permalink"></a></h3><p>Set the <code>JULIA_HDF5_PATH</code> environment variable to the top-level installation directory of the HDF5 libraries compiled with parallel support are found. Then run <code>]build HDF5</code> from Julia. Note that the selected HDF5 library must be linked to the MPI library chosen in the previous section. Also note that HDF5 library versions older than 0.10.4 are not supported by HDF5.jl. For the set-up to be persistent across HDF5.jl updates, consider setting <code>JULIA_HDF5_PATH</code> in <code>~/.bashrc</code> or similar.</p><p>See the <a href="https://github.com/JuliaIO/HDF5.jl#installation">HDF5.jl README</a> for details.</p><h3 id=".-Loading-PencilIO"><a class="docs-heading-anchor" href="#.-Loading-PencilIO">3. Loading PencilIO</a><a id=".-Loading-PencilIO-1"></a><a class="docs-heading-anchor-permalink" href="#.-Loading-PencilIO" title="Permalink"></a></h3><p>In the <code>PencilIO</code> module, the HDF5.jl package is lazy-loaded using <a href="https://github.com/JuliaPackaging/Requires.jl">Requires</a>. This means that, in Julia code, <code>PencilArrays</code> must be loaded <em>after</em><code>HDF5</code> for parallel I/O functionality to be available.</p><p>The following order of <code>using</code>s ensures that parallel I/O support is available:</p><pre><code class="language-julia">using MPI
using HDF5
using PencilArrays</code></pre><h2 id="Library"><a class="docs-heading-anchor" href="#Library">Library</a><a id="Library-1"></a><a class="docs-heading-anchor-permalink" href="#Library" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" href="#PencilArrays.PencilIO.ParallelIODriver" id="PencilArrays.PencilIO.ParallelIODriver"><code>PencilArrays.PencilIO.ParallelIODriver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ParallelIODriver</code></pre><p>Abstract type specifying a parallel I/O driver.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/PencilIO.jl#LL11-L15" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#PencilArrays.PencilIO.MPIIODriver" id="PencilArrays.PencilIO.MPIIODriver"><code>PencilArrays.PencilIO.MPIIODriver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MPIIODriver(; sequential = false, uniqueopen = false, deleteonclose = false)</code></pre><p>MPI-IO driver using the MPI.jl package.</p><p>Keyword arguments are passed to <a href="https://juliaparallel.github.io/MPI.jl/latest/io/#MPI.File.open"><code>MPI.File.open</code></a>.</p><p>This driver writes binary data along with a JSON file containing metadata. When reading data, this JSON file is expected to be present along with the raw data file.</p></div><a class="docs-sourcelink" href="https://github.com/JuliaLang/julia/blob/788b2c77c10c2160f4794a4d4b6b81a95a90940c/base/#L0-L11" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#PencilArrays.PencilIO.PHDF5Driver" id="PencilArrays.PencilIO.PHDF5Driver"><code>PencilArrays.PencilIO.PHDF5Driver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PHDF5Driver(; fcpl, fapl)</code></pre><p>Parallel HDF5 driver using the HDF5.jl package.</p><p>HDF5 file creation and file access property lists may be specified via the <code>fcpl</code> and <code>fapl</code> keyword arguments respectively.</p><p>Note that the MPIO file access property list does not need to be set, as this is done automatically by this driver when the file is opened.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/hdf5.jl#LL6-L16" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#PencilArrays.PencilIO.MPIFile" id="PencilArrays.PencilIO.MPIFile"><code>PencilArrays.PencilIO.MPIFile</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MPIFile</code></pre><p>Wraps a <code>MPI.FileHandle</code>, also including file position information and metadata.</p><p>File position is updated when reading and writing data, and is independent of the individual and shared file pointers defined by MPI.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/mpi_io.jl#LL31-L38" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#Base.open" id="Base.open"><code>Base.open</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">open([f::Function], driver::ParallelIODriver, filename, comm::MPI.Comm; keywords...)</code></pre><p>Open parallel file using the chosen driver.</p><p><strong>Keyword arguments</strong></p><p>Supported keyword arguments include:</p><ul><li><p>open mode arguments: <code>read</code>, <code>write</code>, <code>create</code>, <code>append</code> and <code>truncate</code>. These have the same behaviour and defaults as <code>Base.open</code>. Some of them may be ignored by the chosen driver (see driver-specific docs).</p></li><li><p>as in <a href="https://juliaparallel.github.io/MPI.jl/latest/io/#MPI.File.open"><code>MPI.File.open</code></a>, other arguments are passed via an <code>MPI.Info</code> object.</p></li></ul><p>Note that driver-specific options (such as HDF5 property lists) must be passed to each driver's constructor.</p><p><strong>See also</strong></p><ul><li><a href="#Base.open"><code>open(::MPIIODriver)</code></a> for MPI-IO specific options</li><li><a href="#Base.open"><code>open(::PHDF5Driver)</code></a> for HDF5 specific options</li></ul></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/PencilIO.jl#LL18-L42" target="_blank">source</a></section><section><div><pre><code class="language-none">open([f::Function], driver::MPIIODriver, filename, comm::MPI.Comm; keywords...)</code></pre><p>Open parallel file using the MPI-IO driver.</p><p>See <a href="#Base.open"><code>open(::ParallelIODriver)</code></a> for common options for all drivers.</p><p>Driver-specific options may be passed via the <code>driver</code> argument. See <a href="#PencilArrays.PencilIO.MPIIODriver"><code>MPIIODriver</code></a> for details.</p><p><strong>Driver notes</strong></p><ul><li>the <code>truncate</code> keyword is ignored.</li></ul></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/mpi_io.jl#LL110-L123" target="_blank">source</a></section><section><div><pre><code class="language-none">open([f::Function], driver::PHDF5Driver, filename, comm::MPI.Comm; keywords...)</code></pre><p>Open parallel file using the Parallel HDF5 driver.</p><p>See <a href="#Base.open"><code>open(::ParallelIODriver)</code></a> for common options for all drivers.</p><p>Driver-specific options may be passed via the <code>driver</code> argument. See <a href="#PencilArrays.PencilIO.PHDF5Driver"><code>PHDF5Driver</code></a> for details.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/hdf5.jl#LL85-L94" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#Base.setindex!" id="Base.setindex!"><code>Base.setindex!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">setindex!(file::MPIFile, x::MaybePencilArrayCollection,
          name::AbstractString; chunks = false, collective = true, infokws...)</code></pre><p>Write <a href="../PencilArrays/#PencilArrays.PencilArray"><code>PencilArray</code></a> to binary file using MPI-IO.</p><p><strong>Optional arguments</strong></p><ul><li><p>if <code>chunks = true</code>, data is written in contiguous blocks, with one block per process. Otherwise, each process writes to discontiguous sections of disk, using <code>MPI.File.set_view!</code> and custom datatypes. Note that discontiguous I/O (the default) is more convenient, as it allows to read back the data using a different number or distribution of MPI processes.</p></li><li><p>if <code>collective = true</code>, the dataset is written collectivelly. This is usually recommended for performance.</p></li><li><p>when writing discontiguous blocks, additional keyword arguments are passed via an <code>MPI.Info</code> object to <code>MPI.File.set_view!</code>. This is ignored if <code>chunks = true</code>.</p></li></ul></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/mpi_io.jl#LL133-L154" target="_blank">source</a></section><section><div><pre><code class="language-none">setindex!(
    g::Union{HDF5.File,HDF5.Group}, x::MaybePencilArrayCollection,
    name::AbstractString; chunks = false, collective = true, prop_lists...,
)</code></pre><p>Write <a href="../PencilArrays/#PencilArrays.PencilArray"><code>PencilArray</code></a> or <a href="../PencilArrays/#PencilArrays.PencilArrayCollection"><code>PencilArrayCollection</code></a> to parallel HDF5 file.</p><p>For performance reasons, the memory layout of the data is conserved. In other words, if the dimensions of a <code>PencilArray</code> are permuted in memory, then the data is written in permuted form.</p><p>In the case of a <code>PencilArrayCollection</code>, each array of the collection is written as a single component of a higher-dimension dataset.</p><p><strong>Optional arguments</strong></p><ul><li><p>if <code>chunks = true</code>, data is written in chunks, with roughly one chunk per MPI process. This may (or may not) improve performance in parallel filesystems.</p></li><li><p>if <code>collective = true</code>, the dataset is written collectivelly. This is usually recommended for performance.</p></li><li><p>additional property lists may be specified by key-value pairs in <code>prop_lists</code>, following the <a href="https://juliaio.github.io/HDF5.jl/stable/#Passing-parameters">HDF5.jl syntax</a>. These property lists take precedence over keyword arguments. For instance, if the <code>dxpl_mpio = HDF5.H5FD_MPIO_COLLECTIVE</code> option is passed, then the value of the <code>collective</code> argument is ignored.</p></li></ul><p><strong>Property lists</strong></p><p>Property lists are passed to <a href="https://portal.hdfgroup.org/display/HDF5/H5D_CREATE2"><code>h5d_create</code></a> and <a href="https://portal.hdfgroup.org/display/HDF5/H5D_WRITE"><code>h5d_write</code></a>. The following property types are recognised:</p><ul><li><a href="https://portal.hdfgroup.org/display/HDF5/Attribute+and+Link+Creation+Properties">link creation properties</a>,</li><li><a href="https://portal.hdfgroup.org/display/HDF5/Dataset+Creation+Properties">dataset creation properties</a>,</li><li><a href="https://portal.hdfgroup.org/display/HDF5/Dataset+Access+Properties">dataset access properties</a>,</li><li><a href="https://portal.hdfgroup.org/display/HDF5/Dataset+Transfer+Properties">dataset transfer properties</a>.</li></ul><p><strong>Example</strong></p><p>Open a parallel HDF5 file and write some <code>PencilArray</code>s to the file:</p><pre><code class="language-julia">pencil = Pencil(#= ... =#)
u = PencilArray{Float64}(undef, pencil)
v = similar(u)

# [fill the arrays with interesting values...]

comm = get_comm(u)

open(PHDF5Driver(), "filename.h5", comm, write=true) do ff
    ff["u", chunks=true] = u
    ff["uv"] = (u, v)  # this is a two-component PencilArrayCollection (assuming equal dimensions of `u` and `v`)
end</code></pre></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/hdf5.jl#LL133-L195" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#Base.read!" id="Base.read!"><code>Base.read!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">read!(file::MPIFile, x::PencilArray, name::AbstractString;
      collective = true, infokws...)</code></pre><p>Read binary data from an MPI-IO stream, filling in <a href="../PencilArrays/#PencilArrays.PencilArray"><code>PencilArray</code></a>.</p><p>See <a href="#Base.setindex!"><code>setindex!</code></a> for details on keyword arguments.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/mpi_io.jl#LL196-L203" target="_blank">source</a></section><section><div><pre><code class="language-none">read!(g::Union{HDF5File,HDF5Group}, x::MaybePencilArrayCollection,
      name::AbstractString; collective=true, prop_lists...)</code></pre><p>Read <a href="../PencilArrays/#PencilArrays.PencilArray"><code>PencilArray</code></a> or <a href="../PencilArrays/#PencilArrays.PencilArrayCollection"><code>PencilArrayCollection</code></a> from parallel HDF5 file.</p><p>See <a href="#Base.setindex!"><code>setindex!</code></a> for details on optional arguments.</p><p><strong>Property lists</strong></p><p>Property lists are passed to <a href="https://portal.hdfgroup.org/display/HDF5/H5D_OPEN2"><code>h5d_open</code></a> and <a href="https://portal.hdfgroup.org/display/HDF5/H5D_READ"><code>h5d_read</code></a>. The following property types are recognised:</p><ul><li><a href="https://portal.hdfgroup.org/display/HDF5/Dataset+Access+Properties">dataset access properties</a>,</li><li><a href="https://portal.hdfgroup.org/display/HDF5/Dataset+Transfer+Properties">dataset transfer properties</a>.</li></ul><p><strong>Example</strong></p><p>Open a parallel HDF5 file and read some <code>PencilArray</code>s:</p><pre><code class="language-julia">pencil = Pencil(#= ... =#)
u = PencilArray{Float64}(undef, pencil)
v = similar(u)

comm = get_comm(u)
info = MPI.Info()

open(PHDF5Driver(), "filename.h5", comm, read=true) do ff
    read!(ff, u, "u")
    read!(ff, (u, v), "uv")
end</code></pre></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/hdf5.jl#LL245-L280" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#PencilArrays.PencilIO.hdf5_has_parallel" id="PencilArrays.PencilIO.hdf5_has_parallel"><code>PencilArrays.PencilIO.hdf5_has_parallel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hdf5_has_parallel() -&gt; Bool</code></pre><p>Returns <code>true</code> if the loaded HDF5 libraries support MPI-IO.</p></div><a class="docs-sourcelink" href="https://github.com/jipolanco/PencilArrays.jl/blob/0f26f415cfacbd93d1e801fb20910eda1086c883/src/PencilIO/hdf5.jl#LL56-L60" target="_blank">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#PencilArrays.PencilIO.MPIFile"><code>PencilArrays.PencilIO.MPIFile</code></a></li><li><a href="#PencilArrays.PencilIO.MPIIODriver"><code>PencilArrays.PencilIO.MPIIODriver</code></a></li><li><a href="#PencilArrays.PencilIO.PHDF5Driver"><code>PencilArrays.PencilIO.PHDF5Driver</code></a></li><li><a href="#PencilArrays.PencilIO.ParallelIODriver"><code>PencilArrays.PencilIO.ParallelIODriver</code></a></li><li><a href="#Base.open"><code>Base.open</code></a></li><li><a href="#Base.read!"><code>Base.read!</code></a></li><li><a href="#Base.setindex!"><code>Base.setindex!</code></a></li><li><a href="#PencilArrays.PencilIO.hdf5_has_parallel"><code>PencilArrays.PencilIO.hdf5_has_parallel</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Transpositions/">« Global MPI operations</a><a class="docs-footer-nextpage" href="../PencilArrays_timers/">Measuring performance »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 28 January 2021 21:34">Thursday 28 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>